{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgOBy7swGuuE"
   },
   "source": [
    "# Hate Speech Detection with BERT, Adversarial Training (FGM), and Explainability\n",
    "\n",
    "This notebook implements a hate speech/offensive language detection model based on the project proposal. It fine-tunes a pre-trained BERT model using PyTorch, incorporating:\n",
    "\n",
    "1.  **Data Loading & Preprocessing:** Handles TSV/CSV files, basic text cleaning, and preparation for BERT.\n",
    "2.  **BERT Fine-tuning:** Uses Hugging Face Transformers for model loading and training.\n",
    "3.  **Adversarial Training:** Implements the Fast Gradient Method (FGM) on embeddings as an optional technique to improve robustness.\n",
    "4.  **Evaluation:** Calculates standard classification metrics (Accuracy, F1, Precision, Recall) and generates reports/visualizations.\n",
    "5.  **Explainability:** Provides basic attention visualization to understand model focus.\n",
    "6.  **Configuration:** Key parameters are set in a dedicated cell for easy experimentation.\n",
    "7.  **Early Stopping:** Optional mechanism to prevent overfitting.\n",
    "8.  **Artifact Saving:** Saves the trained model, tokenizer, results, and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNOyi0AGuuG"
   },
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up basic configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "URTBmDDhGuuG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "# Check if sklearn exists before printing version (might not if running on minimal env)\n",
    "try:\n",
    "    import sklearn\n",
    "    print(f\"Scikit-learn found.\")\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-ajgg-6GuuH"
   },
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set hyperparameters, file paths, model name, and feature flags here. Adjust these values for your specific dataset and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: /home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder\n",
      "Root contents: ['Pedro_BiLSTM.py', '.gitignore', 'HASOCData', 'ProjectNLP_Hate_Speech_Detection_Group_5.ipynb', 'OlidPreprcessed', 'Project_NLP_ADL.pdf', 'Project_OLID_Attention.ipynb', 'Project-Visualizing_Attention.ipynb', 'Pedro_BiLSTM_KFold_HParam.py', 'model_output', '.ipynb_checkpoints']\n",
      "Data folder contents: ['english_dataset.tsv', 'hasoc2019_en_test-2919.tsv', '.ipynb_checkpoints']\n",
      "HASOCData contents (if any): ['english_dataset.tsv', 'hasoc2019_en_test-2919.tsv', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working dir:\", os.getcwd())\n",
    "print(\"Root contents:\", os.listdir(os.getcwd()))\n",
    "print(\"Data folder contents:\", os.listdir(os.path.join(os.getcwd(), 'HASOCData')))\n",
    "print(\"HASOCData contents (if any):\", os.listdir(os.path.join(os.getcwd(), 'HASOCData')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "q3R7tNFfGuuH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base dir: /home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder\n",
      "Train file: /home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder/HASOCData/english_dataset.tsv\n",
      "Configuration saved to config.json\n"
     ]
    }
   ],
   "source": [
    "# --- Core Configuration ---\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 128  # Max sequence length for BERT tokenizer\n",
    "BATCH_SIZE = 16 # Reduce if facing GPU memory issues\n",
    "EPOCHS = 4     # Number of training epochs\n",
    "LEARNING_RATE = 2e-5 # Standard learning rate for BERT fine-tuning\n",
    "SEED = 42      # Random seed for reproducibility\n",
    "OUTPUT_DIR = 'model_output' # Directory to save model, results, plots\n",
    "VAL_SPLIT_SIZE = 0.1 # Proportion of training data to use for validation\n",
    "\n",
    "# --- Dataset Configuration ---\n",
    "BASE_DIR = os.getcwd()\n",
    "print(\"Base dir:\", BASE_DIR)\n",
    "# Choose one dataset type to configure\n",
    "DATASET_TYPE = 'HASOC' # Options: 'OLID', 'HASOC', 'OffenseEval'\n",
    "# For OLID & OffenseEval use 'a','b','c'; for HASOC use '1','2','3'\n",
    "SUBTASK = '1'        # e.g. HASOC subtask 1 (task_1), 2 (task_2), or 3 (task_3)\n",
    "\n",
    "\n",
    "# File paths\n",
    "if DATASET_TYPE == 'OLID':\n",
    "    DATA_DIR   = os.path.join(BASE_DIR, 'OlidPreprcessed')\n",
    "    TRAIN_FILE = os.path.join(DATA_DIR, 'OLID_Tain_ATUSER_URL_EmojiRemoved_Pedro.txt')\n",
    "    print(f\"Train file: {TRAIN_FILE}\")\n",
    "    \n",
    "    # pick the right test file for a, b or c\n",
    "    TEST_FILE  = os.path.join(\n",
    "        DATA_DIR,\n",
    "        f'OLID_TEST_{SUBTASK.upper()}_ATUSER_URL_EmojiRemoved_Pedro.txt'\n",
    "    )\n",
    "    TEST_LABELS_FILE = None\n",
    "    TEXT_COLUMN = 'tweet'\n",
    "    \n",
    "    # label column + map per subtask\n",
    "    LABEL_COLUMN = f'subtask_{SUBTASK.lower()}'\n",
    "    if SUBTASK == 'a':\n",
    "        LABEL_MAP = {'NOT': 0, 'OFF': 1}\n",
    "    elif SUBTASK == 'b':\n",
    "        LABEL_MAP = {'UNT': 0, 'TIN': 1}\n",
    "    else:  # c\n",
    "        LABEL_MAP = {'IND': 0, 'GRP': 1, 'OTH': 2}\n",
    "    NUM_LABELS = len(LABEL_MAP)\n",
    "\n",
    "\n",
    "elif DATASET_TYPE == 'HASOC':\n",
    "    # include the Project_folder in path\n",
    "    DATA_DIR    = os.path.join(BASE_DIR, 'HASOCData')\n",
    "    TRAIN_FILE  = os.path.join(DATA_DIR, 'english_dataset.tsv')\n",
    "    print(f\"Train file: {TRAIN_FILE}\")\n",
    "    TEST_FILE   = os.path.join(DATA_DIR, 'hasoc2019_en_test-2919.tsv')\n",
    "    TEST_LABELS_FILE = None\n",
    "\n",
    "    TEXT_COLUMN  = 'tweet'\n",
    "    LABEL_COLUMN = f'task_{SUBTASK}'\n",
    "    if SUBTASK == '1':\n",
    "        LABEL_MAP = {'NOT': 0, 'HOF': 1}\n",
    "    elif SUBTASK == '2':\n",
    "        LABEL_MAP = {'NOT': 0, 'OFF': 1}\n",
    "    else:  # '3'\n",
    "        LABEL_MAP = {'NOT': 0, 'PROF': 1}\n",
    "    NUM_LABELS = len(LABEL_MAP)\n",
    "\n",
    "\n",
    "elif DATASET_TYPE == 'OffenseEval':\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'OffenseEval')\n",
    "    # Train: all nine parts for subtask A, or distant files for B/C\n",
    "    if SUBTASK == 'a':\n",
    "        part_paths = [os.path.join(DATA_DIR, f'task_a_part{i}.xlsx') for i in range(1, 10)]\n",
    "        # load & concat all parts:\n",
    "        TRAIN_FILE = None\n",
    "        train_dfs = [pd.read_excel(p) for p in part_paths if os.path.exists(p)]\n",
    "        df_train_all = pd.concat(train_dfs, ignore_index=True)\n",
    "    elif SUBTASK == 'b':\n",
    "        TRAIN_FILE = os.path.join(DATA_DIR, 'task_b_distant.xlsx')\n",
    "    else:  # 'c'\n",
    "        TRAIN_FILE = os.path.join(DATA_DIR, 'task_c_distant_ann.xlsx')\n",
    "\n",
    "    TEST_DIR = DATA_DIR\n",
    "    TEST_FILE = os.path.join(TEST_DIR, f'test_{SUBTASK}.tsv')  # or whatever your naming is\n",
    "    TEST_LABELS_FILE = None\n",
    "\n",
    "    TEXT_COLUMN  = 'tweet'\n",
    "    LABEL_COLUMN = f'subtask_{SUBTASK}'\n",
    "    if SUBTASK == 'a':\n",
    "        LABEL_MAP = {'NOT': 0, 'OFF': 1}\n",
    "    elif SUBTASK == 'b':\n",
    "        LABEL_MAP = {'UNT': 0, 'TIN': 1}\n",
    "    else:  # 'c'\n",
    "        LABEL_MAP = {'IND': 0, 'GRP': 1, 'OTH': 2}\n",
    "    NUM_LABELS = len(LABEL_MAP)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid DATASET_TYPE. Choose from 'OLID', 'HASOC', 'OffenseEval'.\")\n",
    "\n",
    "# --- Feature Flags ---\n",
    "USE_FGM = True # Set to True to enable Fast Gradient Method adversarial training\n",
    "ADVERSARIAL_EPS = 0.01 # Epsilon for FGM perturbation (if USE_FGM is True)\n",
    "\n",
    "USE_EARLY_STOPPING = True # Set to True to enable early stopping\n",
    "PATIENCE = 3 # Number of epochs to wait for improvement before stopping (if USE_EARLY_STOPPING is True)\n",
    "\n",
    "# --- Create output directory ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Save Configuration to JSON (for record keeping) ---\n",
    "config_dict = {\n",
    "    'MODEL_NAME': MODEL_NAME,\n",
    "    'MAX_LEN': MAX_LEN,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'EPOCHS': EPOCHS,\n",
    "    'LEARNING_RATE': LEARNING_RATE,\n",
    "    'SEED': SEED,\n",
    "    'OUTPUT_DIR': OUTPUT_DIR,\n",
    "    'DATASET_TYPE': DATASET_TYPE,\n",
    "    'BASE_DIR': BASE_DIR,\n",
    "    'TRAIN_FILE': locals().get('TRAIN_FILE'),\n",
    "    'TEST_FILE': locals().get('TEST_FILE'),\n",
    "    'TEST_LABELS_FILE': TEST_LABELS_FILE,\n",
    "    'TEXT_COLUMN': TEXT_COLUMN,\n",
    "    'LABEL_COLUMN': LABEL_COLUMN,\n",
    "    'LABEL_MAP': LABEL_MAP,\n",
    "    'NUM_LABELS': NUM_LABELS,\n",
    "    'VAL_SPLIT_SIZE': VAL_SPLIT_SIZE,\n",
    "    'USE_FGM': USE_FGM,\n",
    "    'ADVERSARIAL_EPS': ADVERSARIAL_EPS if USE_FGM else None,\n",
    "    'USE_EARLY_STOPPING': USE_EARLY_STOPPING,\n",
    "    'PATIENCE': PATIENCE if USE_EARLY_STOPPING else None\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'config.json'), 'w') as f:\n",
    "    json.dump(config_dict, f, indent=4)\n",
    "\n",
    "print(\"Configuration saved to config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhBCS2OrGuuI"
   },
   "source": [
    "## 3. Environment Setup\n",
    "\n",
    "Set random seeds for reproducibility and select the compute device (GPU if available, otherwise CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "gSVUKi5AGuuI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Sets the seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        # These two lines are for deterministic behavior, can slightly slow down training\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Select device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')\n",
    "\n",
    "# Rough Training Time Estimate (for RTX 2080 Ti):\n",
    "# Depending on dataset size (e.g., ~10k-100k samples) and MAX_LEN,\n",
    "# expect training time to be roughly:\n",
    "# - Small dataset (~10k): Few minutes per epoch.\n",
    "# - Medium dataset (~50k-100k): 15-60 minutes per epoch.\n",
    "# - Large dataset (>100k): Potentially several hours per epoch.\n",
    "# FGM adds a small overhead (extra forward/backward pass per step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeTRh_0hGuuI"
   },
   "source": [
    "## 4. Data Loading and Preprocessing\n",
    "\n",
    "Load data from files, perform basic cleaning, map labels, and split into train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "M-3w0ibtGuuI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text looks good.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Basic text cleaning for social media text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower() # Lowercase\n",
    "    # Replace user mentions (keeping a generic token might be useful)\n",
    "    text = re.sub(r'@\\w+', '@USER', text)\n",
    "    # Optional: Replace URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', 'HTTPURL', text)\n",
    "    # Optional: Remove punctuation (Generally NOT recommended for BERT initially)\n",
    "    # import string\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Optional: Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Quick sanity‐check\n",
    "assert preprocess_text(\"Hello  WORLD!!\") == \"hello world!!\"\n",
    "assert preprocess_text(\"@john check this out\") == \"@USER check this out\"\n",
    "print(\"Preprocessed text looks good.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder/HASOCData/english_dataset.tsv' (sep='\t')…\n",
      "✔️ Loaded with sep='\t', shape=(5852, 5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Robust file loading + tests\n",
    "def load_data(file_path: str, sep: str = '\\t') -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load a TSV or CSV file, falling back if necessary.\"\"\"\n",
    "    print(f\"Loading {file_path!r} (sep='{sep}')…\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=sep, quoting=3, on_bad_lines='warn')\n",
    "        print(f\"✔️ Loaded with sep='{sep}', shape={df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed with sep='{sep}': {e}\")\n",
    "\n",
    "    if sep == '\\t':\n",
    "        print(\"→ Retrying with sep=','…\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, on_bad_lines='warn')\n",
    "            print(f\"✔️ Loaded with sep=',', shape={df.shape}\")\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Still failed: {e2}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "# You can test on a small temp CSV/TSV if you like\n",
    "# e.g. \n",
    "DATA_DIR    = os.path.join(BASE_DIR, 'HASOCData')\n",
    "TRAIN_FILE  = os.path.join(DATA_DIR, 'english_dataset.tsv')\n",
    "df = load_data(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 (updated): Full pipeline that tolerates unlabeled OLID test files\n",
    "def load_and_preprocess_data(\n",
    "    train_path:    str,\n",
    "    test_path:     str,\n",
    "    text_col:      str,\n",
    "    label_col:     str,\n",
    "    label_map:     Dict[str, int],\n",
    "    test_labels_path: Optional[str] = None,\n",
    "    val_split:     float = 0.1,\n",
    "    seed:          int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"Load train/test, apply preprocess_text, map labels, then split.\n",
    "       If the test file lacks label_col, we still return the test set\n",
    "       with clean_text (no 'label' column).\"\"\"\n",
    "    # --- Load ---\n",
    "    df_train = load_data(train_path)\n",
    "    if df_train is None:\n",
    "        raise RuntimeError(f\"Cannot load train data at {train_path}\")\n",
    "    df_test = load_data(test_path)\n",
    "    \n",
    "    # --- Validate train columns ---\n",
    "    print(text_col, label_col, df_train.columns)\n",
    "    missing_train = {text_col, label_col} - set(df_train.columns)\n",
    "    if missing_train:\n",
    "        raise ValueError(f\"Train data missing columns: {missing_train}\")\n",
    "\n",
    "    # --- Preprocess train ---\n",
    "    df_train['clean_text'] = df_train[text_col].apply(preprocess_text)\n",
    "    df_train['label']      = df_train[label_col].map(label_map)\n",
    "    orig_train = len(df_train)\n",
    "    df_train.dropna(subset=['clean_text','label'], inplace=True)\n",
    "    df_train = df_train[df_train['clean_text'].str.len()>0]\n",
    "    if len(df_train) < orig_train:\n",
    "        print(f\"⚠️ Dropped {orig_train - len(df_train)} invalid train rows\")\n",
    "    df_train['label'] = df_train['label'].astype(int)\n",
    "    \n",
    "    # --- Preprocess test (if loaded) ---\n",
    "    df_test_clean: Optional[pd.DataFrame] = None\n",
    "    if df_test is not None:\n",
    "        if text_col not in df_test.columns:\n",
    "            print(f\"❌ Test data missing '{text_col}' → discarding test set\")\n",
    "        else:\n",
    "            df_test['clean_text'] = df_test[text_col].apply(preprocess_text)\n",
    "            # If there's a label column, map it; otherwise leave it out\n",
    "            if label_col in df_test.columns:\n",
    "                df_test['label'] = df_test[label_col].map(label_map).astype(int)\n",
    "                df_test_clean = df_test[['clean_text','label']].copy()\n",
    "            else:\n",
    "                print(\"ℹ️ Test file has no labels; returning only clean_text\")\n",
    "                # keep id if you like, otherwise just clean_text\n",
    "                cols = ['clean_text']\n",
    "                if 'id' in df_test.columns:\n",
    "                    cols.insert(0, 'id')\n",
    "                df_test_clean = df_test[cols].copy()\n",
    "    \n",
    "            # drop any empty rows\n",
    "            before = len(df_test_clean)\n",
    "            df_test_clean.dropna(subset=['clean_text'], inplace=True)\n",
    "            df_test_clean = df_test_clean[df_test_clean['clean_text'].str.len()>0]\n",
    "            if len(df_test_clean) < before:\n",
    "                print(f\"⚠️ Dropped {before - len(df_test_clean)} invalid test rows\")\n",
    "\n",
    "    # --- Train/Validation Split ---\n",
    "    if df_train['label'].nunique() < 2 or len(df_train) < 2:\n",
    "        raise RuntimeError(\"Not enough data for train/val split\")\n",
    "    try:\n",
    "        df_tr, df_val = train_test_split(\n",
    "            df_train[['clean_text','label']],\n",
    "            test_size=val_split,\n",
    "            random_state=seed,\n",
    "            stratify=df_train['label']\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"⚠️ Stratified split failed, retrying without stratification\")\n",
    "        df_tr, df_val = train_test_split(\n",
    "            df_train[['clean_text','label']],\n",
    "            test_size=val_split,\n",
    "            random_state=seed\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        df_tr.reset_index(drop=True),\n",
    "        df_val.reset_index(drop=True),\n",
    "        df_test_clean.reset_index(drop=True) if df_test_clean is not None else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder/HASOCData/english_dataset.tsv' (sep='\t')…\n",
      "✔️ Loaded with sep='\t', shape=(5852, 5)\n",
      "Loading '/home/walle/LTU/deeplearning/D7047E_exercise_group_5/Project_folder/HASOCData/hasoc2019_en_test-2919.tsv' (sep='\t')…\n",
      "✔️ Loaded with sep='\t', shape=(1153, 5)\n",
      "tweet task_1 Index(['id', 'tweet', 'task_1', 'task_2', 'task_3'], dtype='object')\n",
      "▶️ Train: 5266 rows; Val: 586 rows; Test: 1153\n",
      "Train label dist:\n",
      " label\n",
      "0    0.613559\n",
      "1    0.386441\n",
      "Name: proportion, dtype: float64\n",
      "Val   label dist:\n",
      " label\n",
      "0    0.614334\n",
      "1    0.385666\n",
      "Name: proportion, dtype: float64\n",
      "Test  label dist:\n",
      " label\n",
      "0    0.750217\n",
      "1    0.249783\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = load_and_preprocess_data(\n",
    "    train_path       = TRAIN_FILE,\n",
    "    test_path        = TEST_FILE,\n",
    "    text_col         = TEXT_COLUMN,\n",
    "    label_col        = LABEL_COLUMN,\n",
    "    label_map        = LABEL_MAP,\n",
    "    test_labels_path = TEST_LABELS_FILE,\n",
    "    val_split        = VAL_SPLIT_SIZE,\n",
    "    seed             = SEED\n",
    ")\n",
    "\n",
    "print(f\"▶️ Train: {len(df_train)} rows; Val: {len(df_val)} rows; \"\n",
    "      f\"Test: {len(df_test) if df_test is not None else 'N/A'}\")\n",
    "\n",
    "print(\"Train label dist:\\n\", df_train['label'].value_counts(normalize=True))\n",
    "print(\"Val   label dist:\\n\", df_val['label'].value_counts(normalize=True))\n",
    "if df_test is not None and 'label' in df_test.columns:\n",
    "    print(\"Test  label dist:\\n\", df_test['label'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"Test  label dist:\\n N/A (test set unlabeled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNlGQw-DGuuJ"
   },
   "source": [
    "## 5. PyTorch Dataset and DataLoader\n",
    "\n",
    "Create a custom PyTorch `Dataset` to handle text tokenization on-the-fly and `DataLoader` for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "445ISyANGuuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for model: bert-base-uncased\n",
      "▶️ Train loader: 5266 samples\n",
      "▶️ Val   loader: 586 samples\n",
      "▶️ Test  loader: 1153 samples\n"
     ]
    }
   ],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for text classification tasks.\"\"\"\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer: BertTokenizer, max_len: int):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "        # only add labels if we have them\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# --- Initialize Tokenizer ---\n",
    "print(f\"Loading tokenizer for model: {MODEL_NAME}\")\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# --- Create train/val datasets & loaders ---\n",
    "train_dataset = TextClassificationDataset(\n",
    "    texts=df_train['clean_text'].tolist(),\n",
    "    labels=df_train['label'].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "val_dataset = TextClassificationDataset(\n",
    "    texts=df_val['clean_text'].tolist(),\n",
    "    labels=df_val['label'].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "persistent_workers = True if torch.__version__ >= '1.7' and torch.cuda.is_available() else False\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=2, persistent_workers=persistent_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=2, persistent_workers=persistent_workers)\n",
    "\n",
    "print(f\"▶️ Train loader: {len(train_dataset)} samples\")\n",
    "print(f\"▶️ Val   loader: {len(val_dataset)} samples\")\n",
    "\n",
    "# --- Create test loader only if 'label' exists ---\n",
    "test_loader = None\n",
    "if df_test is not None and 'label' in df_test.columns and len(df_test) > 0:\n",
    "    test_dataset = TextClassificationDataset(\n",
    "        texts=df_test['clean_text'].tolist(),\n",
    "        labels=df_test['label'].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             num_workers=2, persistent_workers=persistent_workers)\n",
    "    print(f\"▶️ Test  loader: {len(test_dataset)} samples\")\n",
    "else:\n",
    "    print(\"ℹ️ No labeled test set found → skipping test DataLoader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZWDd3hMGuuJ"
   },
   "source": [
    "## 6. Model Loading\n",
    "\n",
    "Load the pre-trained BERT model for sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "WJO3ZE7tGuuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb93ae38726045c7b5333b2637d00834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/file_download.py:627\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    625\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 627\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading pre-trained model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_LABELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Binary classification\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# output_attentions=True, # Set to True if you want attentions *during training*\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# output_hidden_states=True, # Set to True if you want hidden states *during training*\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Check model name and internet connection.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/transformers/modeling_utils.py:3809\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3793\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3794\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   3795\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   3808\u001b[0m     }\n\u001b[0;32m-> 3809\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   3814\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/file_download.py:1159\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1157\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1159\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1172\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/file_download.py:1708\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1707\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1708\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nnlm/lib/python3.8/site-packages/huggingface_hub/file_download.py:627\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    625\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 627\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Loading pre-trained model: {MODEL_NAME}\")\n",
    "try:\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=NUM_LABELS, # Binary classification\n",
    "        # output_attentions=True, # Set to True if you want attentions *during training*\n",
    "        # output_hidden_states=True, # Set to True if you want hidden states *during training*\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Failed to load model {MODEL_NAME}: {e}. Check model name and internet connection.\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "print(\"Model loaded and moved to device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ihuKnCfGuuJ"
   },
   "source": [
    "## 7. Adversarial Training (FGM)\n",
    "\n",
    "Define the Fast Gradient Method (FGM) class to perturb word embeddings during training. This is applied only if `USE_FGM` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_vhfdALGuuJ"
   },
   "outputs": [],
   "source": [
    "class FGM:\n",
    "    \"\"\"\n",
    "    Fast Gradient Method (FGM) for adversarial training on word embeddings.\n",
    "    Applies perturbation to the model's embedding matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, emb_name: str = 'word_embeddings', epsilon: float = 1.0):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.emb_name = emb_name # Usually 'word_embeddings' in BERT\n",
    "        self.backup = {}\n",
    "        self.embedding_layer_param = None\n",
    "\n",
    "        # Find the parameter corresponding to the embedding layer dynamically\n",
    "        for name, param in self.model.named_parameters():\n",
    "            # Check if the parameter's name contains the embedding layer name\n",
    "            if self.emb_name in name:\n",
    "                print(f\"FGM: Found embedding layer parameter: {name}\")\n",
    "                self.embedding_layer_param = param\n",
    "                self.embedding_param_name = name\n",
    "                break\n",
    "\n",
    "        if self.embedding_layer_param is None:\n",
    "            print(f\"Warning: FGM could not find embedding layer parameter named like '{self.emb_name}'. Adversarial training will be disabled.\")\n",
    "\n",
    "    def attack(self):\n",
    "        \"\"\"Calculates and applies the perturbation.\"\"\"\n",
    "        # Only attack during training and if the embedding parameter was found\n",
    "        if self.embedding_layer_param is None or not self.model.training:\n",
    "            return\n",
    "\n",
    "        # Get the parameter and its gradient\n",
    "        param = self.embedding_layer_param\n",
    "        if param.requires_grad and param.grad is not None:\n",
    "             self.backup[self.embedding_param_name] = param.data.clone()\n",
    "             # Calculate the perturbation r_at\n",
    "             norm = torch.norm(param.grad)\n",
    "             if norm != 0 and not torch.isnan(norm):\n",
    "                r_at = self.epsilon * param.grad / norm\n",
    "                param.data.add_(r_at) # Apply the perturbation\n",
    "             # else:\n",
    "                # print(f\"Warning: Zero or NaN norm for gradient of {self.embedding_param_name}. Skipping perturbation.\")\n",
    "        # else:\n",
    "             # print(f\"Warning: Gradient for {self.embedding_param_name} is None or requires_grad=False. Skipping FGM attack for this step.\")\n",
    "\n",
    "\n",
    "    def restore(self):\n",
    "        \"\"\"Restores the original embedding weights.\"\"\"\n",
    "        if self.embedding_layer_param is None:\n",
    "            return\n",
    "\n",
    "        # Restore the parameter data from backup\n",
    "        if self.embedding_param_name in self.backup:\n",
    "            self.embedding_layer_param.data = self.backup[self.embedding_param_name]\n",
    "        self.backup = {} # Clear the backup\n",
    "\n",
    "# Initialize FGM if enabled\n",
    "fgm = None\n",
    "if USE_FGM:\n",
    "    print(\"Initializing FGM...\")\n",
    "    # For Hugging Face BERT, the embeddings are typically model.bert.embeddings.word_embeddings.weight\n",
    "    # We need to find the parameter corresponding to this weight tensor.\n",
    "    # The FGM class now searches for the parameter name containing 'word_embeddings'.\n",
    "    fgm = FGM(model, emb_name='word_embeddings', epsilon=ADVERSARIAL_EPS)\n",
    "    if fgm.embedding_layer_param is None:\n",
    "        print(\"Disabling FGM as embedding layer parameter was not found.\")\n",
    "        USE_FGM = False # Disable if initialization failed\n",
    "else:\n",
    "    print(\"FGM Adversarial Training is disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcjXFAeWGuuK"
   },
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "Define functions for a single training epoch and evaluation, then implement the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWLmg75SGuuK"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module, data_loader: DataLoader, loss_fn: nn.Module, optimizer: torch.optim.Optimizer, device: torch.device, scheduler: torch.optim.lr_scheduler._LRScheduler, n_examples: int, use_fgm: bool, fgm_instance: FGM | None):\n",
    "    \"\"\"Performs a single training epoch.\"\"\"\n",
    "    model.train() # Set model to training mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Wrap your DataLoader\n",
    "    loop = tqdm(\n",
    "        enumerate(data_loader),\n",
    "        total=len(data_loader),\n",
    "        desc=f\"Train batches\",\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    for batch_num, batch in loop:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # --- Standard Forward & Backward Pass ---\n",
    "        optimizer.zero_grad() # Zero gradients at the start of the batch\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy for the batch\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item() # Use .item() for scalar\n",
    "\n",
    "        # Standard backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # --- FGM Attack (if enabled) ---\n",
    "        if use_fgm and fgm_instance is not None:\n",
    "            # Check if FGM was successfully initialized and can attack\n",
    "            if fgm_instance.embedding_layer_param is not None and fgm_instance.embedding_layer_param.grad is not None:\n",
    "                fgm_instance.attack() # Perturb embeddings based on current gradients\n",
    "\n",
    "                # Adversarial forward pass\n",
    "                outputs_adv = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss_adv = outputs_adv.loss\n",
    "\n",
    "                # Adversarial backward pass (gradients accumulate)\n",
    "                loss_adv.backward()\n",
    "\n",
    "                fgm_instance.restore() # Restore original embeddings\n",
    "            # else:\n",
    "                 # print(\"FGM condition not met (embedding param not found or grad is None).\")\n",
    "        # --- End FGM ---\n",
    "\n",
    "        # Clip gradients (optional but often helpful)\n",
    "        # Applies to accumulated gradients if FGM was used\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Update weights and learning rate\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update tqdm postfix\n",
    "        loop.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\":  f\"{(preds==labels).float().mean().item():.4f}\"\n",
    "        })\n",
    "\n",
    "        # Print progress every N batches\n",
    "        if (batch_num + 1) % 100 == 0:\n",
    "             # Calculate batch accuracy using only current batch's data\n",
    "             batch_preds = torch.argmax(outputs.logits, dim=1)\n",
    "             batch_acc = torch.sum(batch_preds == labels).item() / len(labels)\n",
    "             print(f'  Batch {batch_num + 1}/{len(data_loader)}, Loss: {loss.item():.4f}, Batch Acc: {batch_acc:.4f}')\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    # Use correct_predictions accumulated across all batches for total accuracy\n",
    "    accuracy = correct_predictions / n_examples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def eval_model(model: nn.Module, data_loader: DataLoader, device: torch.device, n_examples: int, loss_fn: nn.Module = None):\n",
    "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Handle case where data_loader is None (e.g., test data not loaded)\n",
    "    if data_loader is None or len(data_loader) == 0:\n",
    "        print(\"Warning: Evaluation data loader is empty or None. Skipping evaluation.\")\n",
    "        # Return placeholder values or raise error depending on desired behavior\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0, [], []\n",
    "\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculations\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                # We pass labels here primarily to get the loss calculated by the model\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # If loss_fn is provided, use it explicitly, otherwise use model output loss\n",
    "            if loss_fn:\n",
    "                 explicit_loss = loss_fn(logits, labels)\n",
    "                 total_loss += explicit_loss.item()\n",
    "            else:\n",
    "                 total_loss += loss.item()\n",
    "\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / n_examples\n",
    "\n",
    "    # Calculate other metrics\n",
    "    # Use 'weighted' to account for label imbalance\n",
    "    # Set zero_division=0 to avoid warnings/errors if a class has no predictions/true labels\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    return avg_loss, accuracy, f1, precision, recall, all_labels, all_preds\n",
    "\n",
    "# --- Optimizer and Scheduler ---\n",
    "# Parameters with requires_grad=False will be ignored automatically by AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "\n",
    "# Calculate total training steps\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, # Optional: set a number of warmup steps (e.g., int(0.1 * num_training_steps))\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Loss function (used explicitly in eval, model calculates it internally during training with labels)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# --- Training Loop ---\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "best_epoch = -1\n",
    "\n",
    "print(f\"Starting training on {DATASET_TYPE} subtask {SUBTASK.upper()}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f'\\n--- Epoch {epoch + 1}/{EPOCHS} ---')\n",
    "\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn, # Pass loss_fn even if not explicitly used in train_epoch (can be for logging)\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_dataset), # Use dataset length for total samples\n",
    "        USE_FGM, # Pass the flag\n",
    "        fgm      # Pass the FGM instance\n",
    "    )\n",
    "    print(f'Epoch {epoch + 1} Training   -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "\n",
    "    val_loss, val_acc, val_f1, val_precision, val_recall, _, _ = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        device,\n",
    "        len(val_dataset), # Use dataset length for total samples\n",
    "        loss_fn # Pass loss_fn\n",
    "    )\n",
    "    print(f'Epoch {epoch + 1} Validation -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "\n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "\n",
    "    # --- Early Stopping Check ---\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved ({best_val_loss:.4f} --> {val_loss:.4f}). Saving best model state...')\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        # Save the best model state in memory\n",
    "        best_model_state = deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f'Validation loss did not improve. Counter: {epochs_no_improve}/{PATIENCE}')\n",
    "\n",
    "    # Activate early stopping if enabled and patience is reached\n",
    "    if USE_EARLY_STOPPING and epochs_no_improve >= PATIENCE:\n",
    "        print(f'\\nEarly stopping triggered after {epoch + 1} epochs (no improvement for {PATIENCE} epochs).')\n",
    "        break\n",
    "    # --- End Early Stopping Check ---\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f'\\nTotal Training Time: {total_training_time:.2f} seconds ({total_training_time/60:.2f} minutes)')\n",
    "\n",
    "# --- Load the best model state found during training ---\n",
    "if best_model_state is not None:\n",
    "    print(f\"\\nLoading best model state from epoch {best_epoch + 1} for final evaluation and saving...\")\n",
    "    model.load_state_dict(best_model_state)\n",
    "else:\n",
    "    print(\"\\nWarning: No best model state saved (e.g., training stopped too early, or no improvement). Using the final model state.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAgKX_GuGuuK"
   },
   "source": [
    "## 9. Final Evaluation\n",
    "\n",
    "Evaluate the best performing model (based on validation loss) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FojZGpbeGuuK"
   },
   "outputs": [],
   "source": [
    "# --- Create test DataLoader or inference loader (unchanged) ---\n",
    "test_loader = None\n",
    "inference_only = False\n",
    "\n",
    "if df_test is not None and len(df_test) > 0:\n",
    "    has_labels = 'label' in df_test.columns\n",
    "    test_dataset = TextClassificationDataset(\n",
    "        texts = df_test['clean_text'].tolist(),\n",
    "        labels= df_test['label'].tolist() if has_labels else None,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        persistent_workers=persistent_workers\n",
    "    )\n",
    "    if has_labels:\n",
    "        print(f\"✔️ Built evaluation DataLoader for {len(test_dataset)} labeled test samples.\")\n",
    "    else:\n",
    "        inference_only = True\n",
    "        print(f\"ℹ️ Built inference DataLoader for {len(test_dataset)} test samples (no labels).\")\n",
    "else:\n",
    "    print(\"⚠️ No test data found; skipping test loader.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Run test set evaluation or inference ---\n",
    "if test_loader is None:\n",
    "    print(\"\\nSkipping test set evaluation/inference (no test_loader).\")\n",
    "\n",
    "elif not inference_only:\n",
    "    # ----- EVALUATION WITH LABELS -----\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    test_loss, test_acc, test_f1, test_precision, test_recall, test_labels, test_preds = eval_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        device,\n",
    "        len(test_dataset),\n",
    "        loss_fn\n",
    "    )\n",
    "\n",
    "    # Save predictions for subtask A\n",
    "    inv_label_map = {v:k for k,v in LABEL_MAP.items()}\n",
    "    out_df = pd.DataFrame({\n",
    "        'id':    df_test.get('id', range(len(test_labels))),\n",
    "        'label': test_labels,\n",
    "        'pred':  test_preds,\n",
    "        'pred_str': [inv_label_map[p] for p in test_preds]\n",
    "    })\n",
    "    out_path = os.path.join(OUTPUT_DIR, f'{DATASET_TYPE}_subtaskA_predictions.csv')\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"▶️ Predictions saved to {out_path}\")\n",
    "\n",
    "    # --- NOW PRINT RESULTS WITHOUT OPENING THE CSV ---\n",
    "    print(f'\\nTest Set Results:')\n",
    "    print(f'  Loss:      {test_loss:.4f}')\n",
    "    print(f'  Accuracy:  {test_acc:.4f}')\n",
    "    print(f'  F1-score:  {test_f1:.4f}')\n",
    "    print(f'  Precision: {test_precision:.4f}')\n",
    "    print(f'  Recall:    {test_recall:.4f}')\n",
    "\n",
    "    target_names = [k for k,v in sorted(LABEL_MAP.items(), key=lambda x:x[1])]\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(test_labels, test_preds,\n",
    "                                target_names=target_names,\n",
    "                                digits=4,\n",
    "                                zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(cm)\n",
    "\n",
    "    # (Optional: plotting code here…)\n",
    "\n",
    "elif inference_only:\n",
    "    # ----- INFERENCE-ONLY, NO TRUE LABELS -----\n",
    "    print(\"\\nRunning inference on unlabeled Test Set...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids      = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    inv_label_map = {v:k for k,v in LABEL_MAP.items()}\n",
    "    pred_strs = [inv_label_map[p] for p in all_preds]\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        'id':        df_test.get('id', range(len(all_preds))),\n",
    "        'prediction':    all_preds,\n",
    "        'prediction_str': pred_strs\n",
    "    })\n",
    "    out_path = os.path.join(OUTPUT_DIR,\n",
    "    f'{DATASET_TYPE}_subtask{SUBTASK.upper()}_predictions.csv')\n",
    "\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"▶️ Inference done. Saved predictions to {out_path}\")\n",
    "\n",
    "    # How many examples to display\n",
    "    n_display = 20\n",
    "\n",
    "    # Get unique predicted class labels (e.g. ['NOT','OFF'])\n",
    "    pred_classes = out_df['prediction_str'].unique().tolist()\n",
    "    n_classes = len(pred_classes)\n",
    "    # Compute how many per class (at least one)\n",
    "    per_class = max(1, n_display // n_classes)\n",
    "\n",
    "    # Sample per class\n",
    "    sampled = (\n",
    "        out_df\n",
    "        .groupby('prediction_str', group_keys=False)\n",
    "        .apply(lambda grp: grp.sample(min(len(grp), per_class), random_state=SEED))\n",
    "    )\n",
    "\n",
    "    # If we overshot (e.g. 2 classes × 3 = 6 > 5), just pick n_display at random\n",
    "    if len(sampled) > n_display:\n",
    "        sampled = sampled.sample(n_display, random_state=SEED)\n",
    "\n",
    "    # Finally, shuffle the small sample so it’s not grouped by class\n",
    "    sampled = sampled.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nSample predictions (balanced across predicted classes):\")\n",
    "    print(sampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg7xI7pgGuuK"
   },
   "source": [
    "## 10. Save Artifacts and Results\n",
    "\n",
    "Save the trained model, tokenizer, training history plots, and final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlFpQ8G3GuuK"
   },
   "outputs": [],
   "source": [
    "# After saving artifacts\n",
    "\n",
    "print(\"\\nSaving artifacts...\")\n",
    "\n",
    "# --- Save Model and Tokenizer ---\n",
    "model_save_path = os.path.join(OUTPUT_DIR, 'best_model')\n",
    "try:\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    print(f\"Best model and tokenizer saved to: {model_save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model or tokenizer: {e}\")\n",
    "\n",
    "# --- Plot Training History ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.plot(history['val_f1'], label='Validation F1')\n",
    "plt.title('Accuracy & F1 History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "history_plot_path = os.path.join(OUTPUT_DIR, 'training_history.png')\n",
    "try:\n",
    "    plt.savefig(history_plot_path)\n",
    "    print(f\"Training history plot saved to {history_plot_path}\")\n",
    "    # plt.show() # Uncomment to display inline\n",
    "except Exception as e:\n",
    "    print(f\"Error saving history plot: {e}\")\n",
    "\n",
    "# --- Save Configuration and Results to JSON ---\n",
    "# Reuse config_dict from earlier\n",
    "# Ensure confusion_matrix is serializable\n",
    "cm_data = cm.tolist() if hasattr(cm, 'tolist') else cm\n",
    "\n",
    "results = {\n",
    "    'config': config_dict,\n",
    "    'training_info': {\n",
    "        'epochs_run': len(history['train_loss']),\n",
    "        'total_training_time_seconds': total_training_time,\n",
    "        'best_validation_loss': best_val_loss if best_model_state is not None else None,\n",
    "        'best_epoch': best_epoch if best_model_state is not None else None\n",
    "    },\n",
    "    'history': history,\n",
    "    'test_metrics': {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': test_acc,\n",
    "        'f1_score_weighted': test_f1,\n",
    "        'precision_weighted': test_precision,\n",
    "        'recall_weighted': test_recall\n",
    "    },\n",
    "    'classification_report': report,\n",
    "    'confusion_matrix': cm_data\n",
    "}\n",
    "\n",
    "results_path = os.path.join(OUTPUT_DIR, 'results.json')\n",
    "try:\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Configuration, history and results saved to {results_path}\")\n",
    "except Exception as e:\n",
    "     print(f\"Error saving results JSON: {e}\")\n",
    "\n",
    "print(\"\\nArtifact saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLVFtqdrGuuL"
   },
   "source": [
    "## 11. Explainability (Attention Visualization)\n",
    "\n",
    "Load the trained model with `output_attentions=True` and visualize attention weights for a few examples from the test set. This provides a basic insight into which words the model focused on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bD6_VmP2GuuL"
   },
   "outputs": [],
   "source": [
    "def visualize_attention(model: BertForSequenceClassification, tokenizer: BertTokenizer, text: str, device: torch.device, max_len: int, fig_title: str = \"Average Attention from [CLS] Token (Last Layer)\"):\n",
    "    \"\"\"Generates a basic attention visualization for a given text.\"\"\"\n",
    "\n",
    "    # Preprocess and tokenize the text\n",
    "    processed_text = preprocess_text(text)\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        processed_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    ).to(device) # Move inputs to device\n",
    "\n",
    "    # Ensure model outputs attentions (should have been loaded this way)\n",
    "    if not model.config.output_attentions:\n",
    "        print(\"Error: Model was not loaded with output_attentions=True. Cannot visualize attention.\")\n",
    "        print(\"Please reload the model with `output_attentions=True` before calling this function.\")\n",
    "        return None, None\n",
    "\n",
    "    # Get model output (including attentions)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Passing labels here is optional for visualization, but doesn't hurt\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "    # Extract attentions (tuple of tensors, one for each layer)\n",
    "    # Shape: (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "    # --- Process Attentions (Example: Average last layer's attention from [CLS]) ---\n",
    "    # Get attentions from the last layer\n",
    "    last_layer_attentions = attentions[-1].squeeze(0) # Shape: (num_heads, seq_len, seq_len)\n",
    "\n",
    "    # Average attention scores across all heads\n",
    "    avg_attention = torch.mean(last_layer_attentions, dim=0) # Shape: (seq_len, seq_len)\n",
    "\n",
    "    # Focus on attention from the [CLS] token (index 0) to all other tokens\n",
    "    # Squeeze(0) removes the batch dimension (batch_size=1)\n",
    "    cls_attention = avg_attention[0, :].cpu().numpy() # Shape: (seq_len,)\n",
    "\n",
    "    # Get tokens from the input_ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze(0).cpu().numpy())\n",
    "\n",
    "    # Filter out padding tokens (ids beyond the attention mask)\n",
    "    # Find the last non-padded token index based on attention mask\n",
    "    valid_len = inputs['attention_mask'].squeeze(0).sum().item()\n",
    "    valid_tokens = tokens[:valid_len]\n",
    "    valid_cls_attention = cls_attention[:valid_len]\n",
    "\n",
    "    # Normalize attention scores for better visualization (optional, but often helps)\n",
    "    # Normalize so scores sum to 1 across the sequence\n",
    "    attention_sum = np.sum(valid_cls_attention[1:]) # Sum attention excluding CLS itself\n",
    "    if attention_sum > 0:\n",
    "         valid_cls_attention[1:] = valid_cls_attention[1:] / attention_sum\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Adjust figure size based on number of tokens\n",
    "    fig_width = max(8, len(valid_tokens) * 0.5) # Minimum width 8, then proportional to tokens\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 2))\n",
    "    im = ax.imshow([valid_cls_attention], cmap='viridis', aspect='auto')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(valid_tokens)))\n",
    "    ax.set_yticks([0])\n",
    "    ax.set_xticklabels(valid_tokens, rotation=90, fontsize=10)\n",
    "    ax.set_yticklabels(['[CLS] Attention'])\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(im, orientation='horizontal', fraction=0.05, pad=0.2)\n",
    "    # Optional: Add value labels on heatmap (can be noisy for many tokens)\n",
    "    # for i in range(len(valid_tokens)):\n",
    "    #     ax.text(i, 0, f'{valid_cls_attention[i]:.2f}', ha='center', va='center', color='white' if valid_cls_attention[i] > np.mean(valid_cls_attention) else 'black', fontsize=8)\n",
    "\n",
    "    plt.title(f'{fig_title}\\nText: \"{text[:80]}...\"') # Truncate text for title\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, processed_text # Return figure and processed text\n",
    "\n",
    "# --- Reload model with output_attentions=True ---\n",
    "# Check if test_loader is available, otherwise cannot visualize on test data\n",
    "if test_loader is not None:\n",
    "    print(\"\\nReloading model for attention visualization...\")\n",
    "    # Model was saved to OUTPUT_DIR/best_model\n",
    "    model_path = os.path.join(OUTPUT_DIR, 'best_model')\n",
    "\n",
    "    try:\n",
    "        # Critical: Load with output_attentions=True\n",
    "        # We load from_pretrained from the saved directory, not from the internet\n",
    "        model_for_viz = BertForSequenceClassification.from_pretrained(model_path, output_attentions=True)\n",
    "        model_for_viz.to(device)\n",
    "        model_for_viz.eval() # Ensure evaluation mode\n",
    "        print(\"Model reloaded successfully for visualization.\")\n",
    "\n",
    "        # Get label names from the map for printing\n",
    "        target_names = [k for k, v in sorted(LABEL_MAP.items(), key=lambda item: item[1])]\n",
    "\n",
    "        # --- Visualize Attention for Sample Texts ---\n",
    "        # Take a few samples from the test set dataframe (df_test)\n",
    "        num_samples_to_viz = 5\n",
    "        # Ensure df_test is not None and has enough rows\n",
    "        if df_test is not None and len(df_test) > 0:\n",
    "            sample_indices = df_test.sample(n=min(num_samples_to_viz, len(df_test)), random_state=SEED).index\n",
    "\n",
    "            for i, idx in enumerate(sample_indices):\n",
    "                # Use the already cleaned text from the dataframe\n",
    "                original_text = df_test.loc[idx, 'clean_text']\n",
    "\n",
    "                # Try to get the true label if available, otherwise use dummy 0\n",
    "                true_label_int = df_test.loc[idx, 'label'] if 'label' in df_test.columns else 0\n",
    "                try:\n",
    "                    true_label_str = target_names[true_label_int]\n",
    "                except (IndexError, TypeError):\n",
    "                     true_label_str = f\"Unknown ({true_label_int})\"\n",
    "\n",
    "\n",
    "                print(f\"\\n--- Visualizing Sample {i+1} (Index in test df: {idx}) ---\")\n",
    "                print(f\"Text: {original_text}\")\n",
    "                print(f\"True Label: {true_label_str} ({true_label_int})\")\n",
    "\n",
    "                # Predict with the visualization model to get the predicted label\n",
    "                inputs = tokenizer.encode_plus(original_text, return_tensors='pt', max_length=MAX_LEN, padding='max_length', truncation=True).to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model_for_viz(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "                pred_label_int = torch.argmax(outputs.logits, dim=1).item()\n",
    "                try:\n",
    "                     pred_label_str = target_names[pred_label_int]\n",
    "                except (IndexError, TypeError):\n",
    "                     pred_label_str = f\"Unknown ({pred_label_int})\"\n",
    "                print(f\"Predicted Label: {pred_label_str} ({pred_label_int})\")\n",
    "\n",
    "                # Generate visualization\n",
    "                fig, _ = visualize_attention(model_for_viz, tokenizer, original_text, device, MAX_LEN)\n",
    "                if fig:\n",
    "                    viz_path = os.path.join(OUTPUT_DIR, f'attention_viz_sample_{idx}.png')\n",
    "                    try:\n",
    "                         fig.savefig(viz_path, bbox_inches='tight')\n",
    "                         print(f\"Attention visualization saved to: {viz_path}\")\n",
    "                         plt.show() # Display inline\n",
    "                    except Exception as e:\n",
    "                         print(f\"Error saving attention plot for sample {idx}: {e}\")\n",
    "                         plt.close(fig) # Close the figure if saving failed\n",
    "                else:\n",
    "                     print(\"Skipping visualization due to error in function.\")\n",
    "        else:\n",
    "            print(\"Cannot visualize attention: Test dataframe is empty or None.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during attention visualization setup or execution: {e}\")\n",
    "        print(\"Skipping attention visualization.\")\n",
    "\n",
    "else:\n",
    "     print(\"\\nSkipping attention visualization as test data is not available.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gQ1G60kGuuL"
   },
   "source": [
    "## 12. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrated the process of fine-tuning BERT for hate speech detection, optionally using FGM for adversarial robustness, evaluating performance, and gaining basic insights via attention visualization.\n",
    "\n",
    "**Potential Next Steps:**\n",
    "\n",
    "*   **Hyperparameter Tuning:** Systematically tune `LEARNING_RATE`, `BATCH_SIZE`, `MAX_LEN`, `ADVERSARIAL_EPS`, `PATIENCE` using tools like Optuna or Weights & Biases Sweeps.\n",
    "*   **Dataset Adaptability:** Refine the `load_and_preprocess_data` function to more robustly handle different dataset formats (especially OffenseEval parts) or create dataset-specific loading functions.\n",
    "*   **Advanced Adversarial Training:** Implement PGD (Projected Gradient Descent) or explore libraries like TextAttack for more sophisticated attacks and defenses.\n",
    "*   **Enhanced Explainability:** Integrate libraries like Captum to use methods like Integrated Gradients, SHAP, or LIME for more detailed feature importance analysis.\n",
    "*   **Error Analysis:** Analyze misclassified examples from the test set to understand model weaknesses and potential biases.\n",
    "*   **Model Exploration:** Experiment with other transformer architectures like RoBERTa, DeBERTa, etc.\n",
    "*   **Data Augmentation:** Incorporate techniques like back-translation or synonym replacement (e.g., using `nlpaug`) during training.\n",
    "*   **Weights & Biases Integration:** Uncomment and configure the (currently missing) wandb integration code for comprehensive experiment tracking.\n",
    "*   **Deployment:** Explore ways to deploy the trained model for real-time inference using libraries like FastAPI or Flask."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
